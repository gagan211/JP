{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EMAIL vs CALENDAR QUERY CLASSIFIER\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "This notebook implements a **binary text classifier** using **DistilBERT** to categorize user queries into:\n",
    "\n",
    "- **Class 0**: Gmail-related queries (emails, attachments, inbox, etc.)\n",
    "- **Class 1**: Calendar-related queries (meetings, events, appointments, etc.)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approach\n",
    "\n",
    "1. **Fine-tune** a pre-trained DistilBERT model on labeled query dataset\n",
    "2. Use **PyTorch** for training with AdamW optimizer and learning rate scheduling\n",
    "3. **Evaluate** on hold-out test set with accuracy, precision, recall, F1 metrics\n",
    "4. Implement inference function: `predict_class(query: str) -> int`\n",
    "5. **BONUS Features**:\n",
    "   - Extract time ranges from calendar queries\n",
    "   - Extract people/entities from queries\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Model Selection: Why DistilBERT?\n",
    "\n",
    "| Feature | Benefit |\n",
    "|---------|---------|\n",
    "| **Size** | 66% smaller than BERT-base |\n",
    "| **Performance** | Maintains ~97% of BERT's accuracy |\n",
    "| **Speed** | 60% faster inference |\n",
    "| **Use Case** | Perfect balance for production deployment |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CONSTRAINTS:\n",
    "\n",
    "| Parameter | Value |\n",
    "|-----------|-------|\n",
    "| **Device** | MPS (Mac) / CUDA (GPU) / CPU |\n",
    "| **Max Sequence Length** | 128 tokens |\n",
    "| **Training Batch Size** | 16 |\n",
    "| **Inference Batch Size** | 32-128 |\n",
    "| **Epochs** | 2-3 (small dataset), 2 (large dataset) |\n",
    "| **Learning Rate** | 2e-5 |\n",
    "| **Optimizer** | AdamW with linear warmup |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-04T07:28:19.558214Z",
     "iopub.status.busy": "2025-12-04T07:28:19.557927Z",
     "iopub.status.idle": "2025-12-04T07:28:19.563795Z",
     "shell.execute_reply": "2025-12-04T07:28:19.562896Z",
     "shell.execute_reply.started": "2025-12-04T07:28:19.55819Z"
    }
   },
   "source": [
    "## Implementation\n",
    "\n",
    "- Environment Setup & Import Libraries\n",
    "- Data Loading & Exploration\n",
    "- Data Validation & Quality Checks\n",
    "- Tokenization & Dataset Preparation\n",
    "- Model Initialization\n",
    "- Model Training Loop\n",
    "- Evaluation on Test Set\n",
    "- Error Analysis\n",
    "- Helper Functions\n",
    "- Stress-Test on Model\n",
    "- Testing the Model with Queries (Submission Criteria)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-04T13:49:57.972972Z",
     "iopub.status.busy": "2025-12-04T13:49:57.972405Z",
     "iopub.status.idle": "2025-12-04T13:49:57.982871Z",
     "shell.execute_reply": "2025-12-04T13:49:57.982156Z",
     "shell.execute_reply.started": "2025-12-04T13:49:57.972945Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# ============================================================================\n",
    "# SECTION 1: ENVIRONMENT SETUP\n",
    "# ============================================================================\n",
    "\n",
    "import os\n",
    "import random\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "import calendar\n",
    "from datetime import date, datetime\n",
    "from functools import lru_cache\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\n",
    "    \"mps\" if torch.backends.mps.is_available() \n",
    "    else (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    ")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "if device.type in (\"cuda\", \"mps\"):\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "# Suppress transformers warnings\n",
    "import transformers\n",
    "transformers.logging.set_verbosity_error()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-04T13:49:57.984349Z",
     "iopub.status.busy": "2025-12-04T13:49:57.984039Z",
     "iopub.status.idle": "2025-12-04T13:49:58.005797Z",
     "shell.execute_reply": "2025-12-04T13:49:58.00519Z",
     "shell.execute_reply.started": "2025-12-04T13:49:57.984332Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Define paths\n",
    "DATA_DIR = Path(\"../data/set1\")\n",
    "MODEL_DIR = Path(\"../models/distilbert\")\n",
    "MODEL_SAVE= Path(\"../models/trained/distilbert_trained/\")\n",
    "MODEL_SAVE.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Model configuration\n",
    "MODEL_NAME = \"distilbert-base-uncased\"\n",
    "MAX_LEN = 128\n",
    "BATCH_SIZE = 16\n",
    "EPOCHS = 2\n",
    "LEARNING_RATE = 2e-5\n",
    "\n",
    "print(f\"\\nConfiguration:\")\n",
    "print(f\"  Model: {MODEL_NAME}\")\n",
    "print(f\"  Max length: {MAX_LEN}\")\n",
    "print(f\"  Batch size: {BATCH_SIZE}\")\n",
    "print(f\"  Epochs: {EPOCHS}\")\n",
    "print(f\"  Learning rate: {LEARNING_RATE}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-04T13:49:58.006664Z",
     "iopub.status.busy": "2025-12-04T13:49:58.006447Z",
     "iopub.status.idle": "2025-12-04T13:49:58.397241Z",
     "shell.execute_reply": "2025-12-04T13:49:58.396361Z",
     "shell.execute_reply.started": "2025-12-04T13:49:58.00664Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# SECTION 2: DATA LOADING & EXPLORATION\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"LOADING DATASET\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Load pre-split datasets\n",
    "train_df = pd.read_csv(DATA_DIR / \"mail_calendar_dataset_train.csv\")\n",
    "val_df = pd.read_csv(DATA_DIR / \"mail_calendar_dataset_val.csv\")\n",
    "test_df = pd.read_csv(DATA_DIR / \"mail_calendar_dataset_test.csv\")\n",
    "\n",
    "# Combine for full dataset statistics\n",
    "df = pd.concat([train_df, val_df, test_df], ignore_index=True)\n",
    "\n",
    "print(f\"\\nDataset sizes:\")\n",
    "print(f\"  Total: {len(df):,}\")\n",
    "print(f\"  Train: {len(train_df):,} ({len(train_df)/len(df)*100:.1f}%)\")\n",
    "print(f\"  Val:   {len(val_df):,} ({len(val_df)/len(df)*100:.1f}%)\")\n",
    "print(f\"  Test:  {len(test_df):,} ({len(test_df)/len(df)*100:.1f}%)\")\n",
    "\n",
    "# Class distribution\n",
    "print(f\"\\nClass distribution:\")\n",
    "print(df[\"label\"].value_counts())\n",
    "print(f\"  Gmail (0):    {(df['label'] == 0).sum():,} ({(df['label'] == 0).sum()/len(df)*100:.1f}%)\")\n",
    "print(f\"  Calendar (1): {(df['label'] == 1).sum():,} ({(df['label'] == 1).sum()/len(df)*100:.1f}%)\")\n",
    "\n",
    "# Display sample queries\n",
    "def show_samples(df, label_value, text_col='query', n=5, seed=SEED):\n",
    "    subset = df.loc[df['label'] == label_value, text_col]\n",
    "    k = min(n, len(subset))\n",
    "    label_name = \"Gmail\" if label_value == 0 else \"Calendar\"\n",
    "    print(f\"\\n{label_name} samples ({k} shown):\")\n",
    "    print(\"-\" * 60)\n",
    "    if k == 0:\n",
    "        print(\"  (no rows)\")\n",
    "    else:\n",
    "        for query in subset.sample(n=k, random_state=seed):\n",
    "            print(f\"  • {query}\")\n",
    "\n",
    "show_samples(df, 0)\n",
    "show_samples(df, 1)\n",
    "\n",
    "# Query length distribution\n",
    "df[\"len\"] = df[\"query\"].str.len()\n",
    "print(f\"\\nQuery length statistics:\")\n",
    "print(f\"  Mean: {df['len'].mean():.1f} characters\")\n",
    "print(f\"  Median: {df['len'].median():.0f} characters\")\n",
    "print(f\"  Min: {df['len'].min()}\")\n",
    "print(f\"  Max: {df['len'].max()}\")\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.histplot(df[\"len\"], bins=30, kde=True)\n",
    "plt.title(\"Query Length Distribution\")\n",
    "plt.xlabel(\"Character count\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-04T13:49:58.398363Z",
     "iopub.status.busy": "2025-12-04T13:49:58.398052Z",
     "iopub.status.idle": "2025-12-04T13:49:58.407942Z",
     "shell.execute_reply": "2025-12-04T13:49:58.407164Z",
     "shell.execute_reply.started": "2025-12-04T13:49:58.398344Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# ============================================================================\n",
    "# SECTION 3: DATA VALIDATION & QUALITY CHECKS\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"DATA QUALITY CHECKS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Check for data leakage between splits\n",
    "train_queries = set(train_df['query'].tolist())\n",
    "val_queries = set(val_df['query'].tolist())\n",
    "test_queries = set(test_df['query'].tolist())\n",
    "\n",
    "train_val_overlap = train_queries.intersection(val_queries)\n",
    "train_test_overlap = train_queries.intersection(test_queries)\n",
    "val_test_overlap = val_queries.intersection(test_queries)\n",
    "\n",
    "print(f\"\\nData leakage check:\")\n",
    "print(f\"  Train-Val overlap:  {len(train_val_overlap)} queries\")\n",
    "print(f\"  Train-Test overlap: {len(train_test_overlap)} queries\")\n",
    "print(f\"  Val-Test overlap:   {len(val_test_overlap)} queries\")\n",
    "\n",
    "if train_test_overlap:\n",
    "    print(f\"\\n WARNING: Data leakage detected!\")\n",
    "    print(f\"  Sample overlapping queries: {list(train_test_overlap)[:3]}\")\n",
    "else:\n",
    "    print(f\"\\n No data leakage detected\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-04T13:49:58.409985Z",
     "iopub.status.busy": "2025-12-04T13:49:58.409772Z",
     "iopub.status.idle": "2025-12-04T13:49:59.182592Z",
     "shell.execute_reply": "2025-12-04T13:49:59.18174Z",
     "shell.execute_reply.started": "2025-12-04T13:49:58.409969Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# ============================================================================\n",
    "# SECTION 4: TOKENIZATION & DATASET PREPARATION\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"PREPARING DATASETS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# Load tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "print(f\"\\nTokenizer loaded: {MODEL_NAME}\")\n",
    "\n",
    "# Custom Dataset class\n",
    "class QueryDataset(Dataset):\n",
    "    \"\"\"PyTorch Dataset for query classification.\"\"\"\n",
    "    \n",
    "    def __init__(self, df, tokenizer, max_len):\n",
    "        self.texts = df[\"query\"].tolist()\n",
    "        self.labels = df[\"label\"].tolist()\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts[idx]\n",
    "        label = int(self.labels[idx])\n",
    "        \n",
    "        # Tokenize\n",
    "        encoding = self.tokenizer(\n",
    "            text,\n",
    "            truncation=True,\n",
    "            padding='max_length',\n",
    "            max_length=self.max_len,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].squeeze(0),\n",
    "            'attention_mask': encoding['attention_mask'].squeeze(0),\n",
    "            'labels': torch.tensor(label, dtype=torch.long)\n",
    "        }\n",
    "\n",
    "# Create datasets\n",
    "train_ds = QueryDataset(train_df, tokenizer, MAX_LEN)\n",
    "val_ds = QueryDataset(val_df, tokenizer, MAX_LEN)\n",
    "test_ds = QueryDataset(test_df, tokenizer, MAX_LEN)\n",
    "\n",
    "# Create dataloaders\n",
    "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_loader = DataLoader(test_ds, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "print(f\"\\nDatasets created:\")\n",
    "print(f\"  Train: {len(train_ds):,} samples, {len(train_loader)} batches\")\n",
    "print(f\"  Val:   {len(val_ds):,} samples, {len(val_loader)} batches\")\n",
    "print(f\"  Test:  {len(test_ds):,} samples, {len(test_loader)} batches\")\n",
    "\n",
    "# Demo tokenization\n",
    "sample_text = train_df.iloc[0]['query']\n",
    "sample_encoding = tokenizer(sample_text, truncation=True, padding='max_length', max_length=MAX_LEN)\n",
    "print(f\"\\nSample tokenization:\")\n",
    "print(f\"  Text: '{sample_text}'\")\n",
    "print(f\"  Token IDs shape: {len(sample_encoding['input_ids'])}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-04T13:49:59.183857Z",
     "iopub.status.busy": "2025-12-04T13:49:59.183533Z",
     "iopub.status.idle": "2025-12-04T13:49:59.330914Z",
     "shell.execute_reply": "2025-12-04T13:49:59.330226Z",
     "shell.execute_reply.started": "2025-12-04T13:49:59.183833Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# ============================================================================\n",
    "# SECTION 5: MODEL INITIALIZATION\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"MODEL INITIALIZATION\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "# Load or initialize model\n",
    "num_labels = 2  # Binary classification\n",
    "if MODEL_DIR.exists() and any(MODEL_DIR.iterdir()):\n",
    "    print(f\"\\nLoading fine-tuned model from {MODEL_DIR}\")\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(MODEL_DIR)\n",
    "else:\n",
    "    print(f\"\\nInitializing new model: {MODEL_NAME}\")\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\n",
    "        MODEL_NAME, \n",
    "        num_labels=num_labels\n",
    "    )\n",
    "\n",
    "model.to(device)\n",
    "print(f\" Model loaded to {device}\")\n",
    "\n",
    "# Model architecture summary\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"\\nModel parameters:\")\n",
    "print(f\"  Total: {total_params:,}\")\n",
    "print(f\"  Trainable: {trainable_params:,}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-04T13:49:59.332098Z",
     "iopub.status.busy": "2025-12-04T13:49:59.331819Z",
     "iopub.status.idle": "2025-12-04T13:54:55.037832Z",
     "shell.execute_reply": "2025-12-04T13:54:55.03689Z",
     "shell.execute_reply.started": "2025-12-04T13:49:59.332079Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# SECTION 6: TRAINING LOOP\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TRAINING\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "from torch.optim import AdamW\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Initialize optimizer and scheduler\n",
    "optimizer = AdamW(model.parameters(), lr=LEARNING_RATE)\n",
    "total_steps = len(train_loader) * EPOCHS\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer,\n",
    "    num_warmup_steps=0,\n",
    "    num_training_steps=total_steps\n",
    ")\n",
    "\n",
    "print(f\"\\nTraining configuration:\")\n",
    "print(f\"  Optimizer: AdamW (lr={LEARNING_RATE})\")\n",
    "print(f\"  Scheduler: Linear warmup\")\n",
    "print(f\"  Total steps: {total_steps:,}\")\n",
    "\n",
    "best_val_acc = -1.0\n",
    "\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"EPOCH {epoch}/{EPOCHS}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Training phase\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    train_preds = []\n",
    "    train_labels = []\n",
    "    \n",
    "    train_pbar = tqdm(train_loader, desc=f\"Training\")\n",
    "    for batch in train_pbar:\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Move batch to device\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            labels=labels\n",
    "        )\n",
    "        loss = outputs.loss\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        \n",
    "        # Track metrics\n",
    "        total_loss += loss.item()\n",
    "        preds = torch.argmax(outputs.logits.detach(), dim=-1)\n",
    "        train_preds.extend(preds.cpu().tolist())\n",
    "        train_labels.extend(labels.cpu().tolist())\n",
    "        \n",
    "        train_pbar.set_postfix({'loss': f'{loss.item():.4f}'})\n",
    "    \n",
    "    # Training metrics\n",
    "    train_loss = total_loss / len(train_loader)\n",
    "    train_acc = accuracy_score(train_labels, train_preds)\n",
    "    print(f\"\\nTrain Loss: {train_loss:.4f} | Train Acc: {train_acc:.4f}\")\n",
    "    \n",
    "    # Validation phase\n",
    "    model.eval()\n",
    "    val_preds = []\n",
    "    val_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        val_pbar = tqdm(val_loader, desc=\"Validation\")\n",
    "        for batch in val_pbar:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            \n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            preds = torch.argmax(outputs.logits, dim=-1)\n",
    "            \n",
    "            val_preds.extend(preds.cpu().tolist())\n",
    "            val_labels.extend(labels.cpu().tolist())\n",
    "    \n",
    "    # Validation metrics\n",
    "    val_acc = accuracy_score(val_labels, val_preds)\n",
    "    print(f\"Val Acc: {val_acc:.4f}\")\n",
    "    \n",
    "    # Save best model\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        model.save_pretrained(MODEL_SAVE)\n",
    "        tokenizer.save_pretrained(MODEL_SAVE)\n",
    "        print(f\"Saved best checkpoint (val_acc={val_acc:.4f}) to {MODEL_DIR}\")\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"Training complete! Best validation accuracy: {best_val_acc:.4f}\")\n",
    "print(f\"{'='*80}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-04T13:54:55.039058Z",
     "iopub.status.busy": "2025-12-04T13:54:55.038731Z",
     "iopub.status.idle": "2025-12-04T13:55:01.302843Z",
     "shell.execute_reply": "2025-12-04T13:55:01.302199Z",
     "shell.execute_reply.started": "2025-12-04T13:54:55.039038Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# SECTION 7: EVALUATION ON TEST SET\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TEST SET EVALUATION\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, \n",
    "    precision_recall_fscore_support,\n",
    "    confusion_matrix,\n",
    "    classification_report\n",
    ")\n",
    "\n",
    "# Load best model\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL_DIR)\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "# Run predictions on test set\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(test_loader, desc=\"Testing\"):\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "        \n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        preds = torch.argmax(outputs.logits, dim=-1)\n",
    "        \n",
    "        all_preds.extend(preds.cpu().tolist())\n",
    "        all_labels.extend(labels.cpu().tolist())\n",
    "\n",
    "# Calculate metrics\n",
    "acc = accuracy_score(all_labels, all_preds)\n",
    "precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "    all_labels, all_preds, average='macro'\n",
    ")\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"TEST RESULTS\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"Accuracy:  {acc:.4f} ({acc*100:.2f}%)\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall:    {recall:.4f}\")\n",
    "print(f\"F1 Score:  {f1:.4f}\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
    "plt.title('Confusion Matrix (Counts)')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.xticks([0.5, 1.5], ['Gmail', 'Calendar'])\n",
    "plt.yticks([0.5, 1.5], ['Gmail', 'Calendar'], rotation=0)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "cm_norm = cm.astype('float') / cm.sum(axis=1, keepdims=True)\n",
    "sns.heatmap(cm_norm, annot=True, fmt='.2%', cmap='Greens', cbar=False)\n",
    "plt.title('Confusion Matrix (Normalized)')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.xticks([0.5, 1.5], ['Gmail', 'Calendar'])\n",
    "plt.yticks([0.5, 1.5], ['Gmail', 'Calendar'], rotation=0)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-04T13:55:01.304268Z",
     "iopub.status.busy": "2025-12-04T13:55:01.303685Z",
     "iopub.status.idle": "2025-12-04T13:55:01.315387Z",
     "shell.execute_reply": "2025-12-04T13:55:01.314559Z",
     "shell.execute_reply.started": "2025-12-04T13:55:01.304242Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# SECTION 8: ERROR ANALYSIS\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ERROR ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Create results dataframe\n",
    "test_results = pd.DataFrame({\n",
    "    'query': test_df['query'].tolist(),\n",
    "    'true_label': test_df['label'].tolist(),\n",
    "    'pred_label': all_preds\n",
    "})\n",
    "test_results['correct'] = test_results['true_label'] == test_results['pred_label']\n",
    "\n",
    "correct_count = test_results['correct'].sum()\n",
    "wrong_count = (~test_results['correct']).sum()\n",
    "\n",
    "print(f\"\\nPrediction summary:\")\n",
    "print(f\"  Correct:        {correct_count} / {len(test_results)}\")\n",
    "print(f\"  Misclassified:  {wrong_count}\")\n",
    "\n",
    "# Show misclassified examples\n",
    "if wrong_count > 0:\n",
    "    print(f\"\\n MISCLASSIFIED QUERIES ({wrong_count}):\")\n",
    "    print(\"-\" * 80)\n",
    "    for _, row in test_results[~test_results['correct']].iterrows():\n",
    "        true_label = \"Gmail\" if row['true_label'] == 0 else \"Calendar\"\n",
    "        pred_label = \"Gmail\" if row['pred_label'] == 0 else \"Calendar\"\n",
    "        print(f\"  True: {true_label:8} | Pred: {pred_label:8} | {row['query']}\")\n",
    "else:\n",
    "    print(\"\\n Perfect classification! No errors on test set.\")\n",
    "    print(\"\\nSample predictions:\")\n",
    "    print(\"-\" * 80)\n",
    "    for _, row in test_results.sample(10).iterrows():\n",
    "        label_name = \"Gmail\" if row['true_label'] == 0 else \"Calendar\"\n",
    "        print(f\"  {label_name:8} | {row['query']}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-04T13:55:01.316656Z",
     "iopub.status.busy": "2025-12-04T13:55:01.316379Z",
     "iopub.status.idle": "2025-12-04T13:55:01.334924Z",
     "shell.execute_reply": "2025-12-04T13:55:01.334119Z",
     "shell.execute_reply.started": "2025-12-04T13:55:01.316625Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# SECTION 9: HELPER FUNCTIONS\n",
    "# ============================================================================\n",
    "\n",
    "def extract_time_range(query: str) -> dict:\n",
    "    \"\"\"\n",
    "    Extract time range from calendar queries.\n",
    "    Handles: \"June 2025\", \"May\", \"next Tuesday\", date ranges, etc.\n",
    "    \n",
    "    Returns:\n",
    "        dict with 'from' and 'to' keys (ISO format), or None if no time found\n",
    "    \"\"\"\n",
    "    query_lower = query.lower()\n",
    "    current_year = datetime.now().year\n",
    "    \n",
    "    # Month names mapping\n",
    "    MONTHS = {m.lower(): i for i, m in enumerate(calendar.month_name) if m}\n",
    "    MONTHS.update({m.lower(): i for i, m in enumerate(calendar.month_abbr) if m})\n",
    "    \n",
    "    # Pattern 1: \"Month YYYY\" (e.g., \"June 2025\")\n",
    "    pattern_month_year = r'\\b([a-z]+)\\s+(\\d{4})\\b'\n",
    "    match = re.search(pattern_month_year, query_lower)\n",
    "    if match:\n",
    "        month_name, year_str = match.groups()\n",
    "        month_num = MONTHS.get(month_name)\n",
    "        if month_num and month_num > 0:\n",
    "            year = int(year_str)\n",
    "            last_day = calendar.monthrange(year, month_num)[1]\n",
    "            return {\n",
    "                \"from\": date(year, month_num, 1).isoformat(),\n",
    "                \"to\": date(year, month_num, last_day).isoformat()\n",
    "            }\n",
    "    \n",
    "    # Pattern 2: \"Month\" alone (e.g., \"May\", \"June\") → assume current year\n",
    "    pattern_month_only = r'\\b(' + '|'.join(MONTHS.keys()) + r')\\b'\n",
    "    match = re.search(pattern_month_only, query_lower)\n",
    "    if match:\n",
    "        month_name = match.group(1)\n",
    "        month_num = MONTHS.get(month_name)\n",
    "        if month_num and month_num > 0:\n",
    "            last_day = calendar.monthrange(current_year, month_num)[1]\n",
    "            return {\n",
    "                \"from\": date(current_year, month_num, 1).isoformat(),\n",
    "                \"to\": date(current_year, month_num, last_day).isoformat()\n",
    "            }\n",
    "    \n",
    "    # Pattern 3: \"next/this <weekday>\" (e.g., \"next Tuesday\")\n",
    "    weekdays = ['monday', 'tuesday', 'wednesday', 'thursday', 'friday', 'saturday', 'sunday']\n",
    "    for day in weekdays:\n",
    "        if f'next {day}' in query_lower or f'this {day}' in query_lower:\n",
    "            today = datetime.now().date()\n",
    "            return {\n",
    "                \"from\": today.isoformat(),\n",
    "                \"to\": today.isoformat(),\n",
    "                \"note\": f\"Relative day detected. Compute exact date in production.\"\n",
    "            }\n",
    "    \n",
    "    # Pattern 4: Date range like \"May 1 to May 31\"\n",
    "    pattern_date_range = r'([a-z]+)\\s+(\\d{1,2})\\s+(?:to|-)\\s+([a-z]+)\\s+(\\d{1,2})'\n",
    "    match = re.search(pattern_date_range, query_lower)\n",
    "    if match:\n",
    "        month1, day1, month2, day2 = match.groups()\n",
    "        m1 = MONTHS.get(month1)\n",
    "        m2 = MONTHS.get(month2)\n",
    "        if m1 and m2 and m1 > 0 and m2 > 0:\n",
    "            return {\n",
    "                \"from\": date(current_year, m1, int(day1)).isoformat(),\n",
    "                \"to\": date(current_year, m2, int(day2)).isoformat()\n",
    "            }\n",
    "    \n",
    "    # Pattern 5: Try dateparser if available\n",
    "    try:\n",
    "        import dateparser.search\n",
    "        results = dateparser.search.search_dates(query)\n",
    "        if results:\n",
    "            dt = results[0][1]\n",
    "            iso_date = dt.date().isoformat()\n",
    "            return {\"from\": iso_date, \"to\": iso_date}\n",
    "    except (ImportError, Exception):\n",
    "        pass\n",
    "    \n",
    "    return None\n",
    "\n",
    "\n",
    "def extract_people(query: str) -> list:\n",
    "    \"\"\"\n",
    "    Extract people names from queries using rule-based patterns.\n",
    "    Optimized to avoid duplicates and handle titles correctly.\n",
    "    \n",
    "    Returns:\n",
    "        list of person names found in the query\n",
    "    \"\"\"\n",
    "    found = []\n",
    "    \n",
    "    # Pattern-based extraction (order matters - most specific first!)\n",
    "    patterns = [\n",
    "        # Titles with names (MUST come first to avoid duplicates)\n",
    "        (r'\\b(Dr\\.|Mr\\.|Ms\\.|Mrs\\.)\\s+([A-Z][a-z]+(?:\\s+[A-Z][a-z]+)?)', 2),\n",
    "        # \"from John\" or \"from John Doe\"\n",
    "        (r'\\bfrom\\s+([A-Z][a-z]+(?:\\s+[A-Z][a-z]+)?)', 1),\n",
    "        # \"with Sarah\"\n",
    "        (r'\\bwith\\s+([A-Z][a-z]+(?:\\s+[A-Z][a-z]+)?)', 1),\n",
    "        # \"to Alice\"\n",
    "        (r'\\bto\\s+([A-Z][a-z]+(?:\\s+[A-Z][a-z]+)?)', 1),\n",
    "        # \"Sarah about\"\n",
    "        (r'\\b([A-Z][a-z]+(?:\\s+[A-Z][a-z]+)?)\\s+about', 1),\n",
    "    ]\n",
    "    \n",
    "    for pattern, group_idx in patterns:\n",
    "        for match in re.finditer(pattern, query):\n",
    "            if group_idx == 2:\n",
    "                # For titled names, combine title + name\n",
    "                name = f\"{match.group(1)} {match.group(2)}\".strip()\n",
    "            else:\n",
    "                # For other patterns, just use the name\n",
    "                name = match.group(1).strip()\n",
    "            found.append(name)\n",
    "    \n",
    "    # Deduplicate while preserving order\n",
    "    seen = set()\n",
    "    result = []\n",
    "    for name in found:\n",
    "        key = name.lower()\n",
    "        if key not in seen:\n",
    "            seen.add(key)\n",
    "            result.append(name)\n",
    "    \n",
    "    return result\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-04T13:55:01.336037Z",
     "iopub.status.busy": "2025-12-04T13:55:01.335728Z",
     "iopub.status.idle": "2025-12-04T13:57:50.473981Z",
     "shell.execute_reply": "2025-12-04T13:57:50.473283Z",
     "shell.execute_reply.started": "2025-12-04T13:55:01.33602Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# SECTION 10: STRESS - TEST ON MODEL \n",
    "# ============================================================================\n",
    "\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "# Load the large test dataset\n",
    "large_test_df = pd.read_csv(\"../data/set2/email_calendar_dataset_v2.csv\")\n",
    "print(f\"Large test dataset size: {len(large_test_df):,}\")\n",
    "print(f\"Label distribution:\")\n",
    "print(f\"  Gmail (0): {(large_test_df['label'] == 0).sum():,}\")\n",
    "print(f\"  Calendar (1): {(large_test_df['label'] == 1).sum():,}\")\n",
    "MAX_LEN = 128\n",
    "# Batch prediction on large dataset\n",
    "def batch_predict_large(queries, model, tokenizer, batch_size=128):\n",
    "    \"\"\"Predict in batches for efficiency\"\"\"\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    \n",
    "    for i in tqdm(range(0, len(queries), batch_size), desc=\"Predicting\"):\n",
    "        batch = queries[i:i+batch_size]\n",
    "        enc = tokenizer(batch, padding=True, truncation=True, max_length=MAX_LEN, return_tensors=\"pt\")\n",
    "        enc = {k: v.to(device) for k, v in enc.items()}\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = model(**enc)\n",
    "            preds = torch.argmax(outputs.logits, dim=1).cpu().tolist()\n",
    "            all_preds.extend(preds)\n",
    "    \n",
    "    return all_preds\n",
    "\n",
    "# Run predictions\n",
    "print(\"\\nRunning predictions on larger unknown test queries...\")\n",
    "queries = large_test_df['query'].tolist()\n",
    "labels = large_test_df['label'].tolist()\n",
    "MODEL_DIR = \"../models/trained/distilbert_trained/\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_DIR)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL_DIR)\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "model.eval()\n",
    "preds = batch_predict_large(queries, model, tokenizer, batch_size=128)\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = accuracy_score(labels, preds)\n",
    "precision = precision_score(labels, preds)\n",
    "recall = recall_score(labels, preds)\n",
    "f1 = f1_score(labels, preds)\n",
    "\n",
    "print(f\"\\n\" + \"=\"*60)\n",
    "print(f\"STRESS TEST RESULTS (on {len(large_test_df):,} queries)\")\n",
    "print(f\"=\"*60)\n",
    "print(f\"Accuracy:  {accuracy:.4f} ({accuracy*100:.2f}%)\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall:    {recall:.4f}\")\n",
    "print(f\"F1 Score:  {f1:.4f}\")\n",
    "print(f\"=\"*60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-04T14:06:18.209735Z",
     "iopub.status.busy": "2025-12-04T14:06:18.209427Z",
     "iopub.status.idle": "2025-12-04T14:06:18.408877Z",
     "shell.execute_reply": "2025-12-04T14:06:18.408045Z",
     "shell.execute_reply.started": "2025-12-04T14:06:18.209713Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# SECTION 11: TESTING THE MODEL WITH QUERIES [SUBMISSION CRITERIA]\n",
    "# ============================================================================\n",
    "\n",
    "\n",
    "@lru_cache(maxsize=1)\n",
    "def _get_inference_model():\n",
    "    \"\"\"Load model and tokenizer once (cached for efficiency)\"\"\"\n",
    "    tokenizer = AutoTokenizer.from_pretrained(MODEL_DIR)\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(MODEL_DIR)\n",
    "    model.to(device)\n",
    "    model.eval()  # ← Only call .eval() on MODEL, not tokenizer\n",
    "    return model, tokenizer\n",
    "\n",
    "def predict_class(query: str) -> int:\n",
    "    \"\"\"\n",
    "    Classify a query as Gmail (0) or Calendar (1)\n",
    "    \n",
    "    Args:\n",
    "        query: User's query string\n",
    "        \n",
    "    Returns:\n",
    "        int: 0 for Gmail, 1 for Calendar\n",
    "    \"\"\"\n",
    "    model, tokenizer = _get_inference_model()  # ← Correct order: model, tokenizer\n",
    "    \n",
    "    # Tokenize\n",
    "    encoding = tokenizer(\n",
    "        query,\n",
    "        return_tensors='pt',\n",
    "        truncation=True,\n",
    "        padding=True,\n",
    "        max_length=MAX_LEN\n",
    "    )\n",
    "    encoding = {k: v.to(device) for k, v in encoding.items()}\n",
    "    \n",
    "    # Predict\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**encoding)\n",
    "        logits = outputs.logits\n",
    "        prediction = torch.argmax(logits, dim=-1).item()\n",
    "    \n",
    "    return int(prediction)\n",
    "\n",
    "def analyze_query(query: str) -> dict:\n",
    "    \"\"\"\n",
    "    End-to-end query analysis with all features.\n",
    "    \n",
    "    Returns:\n",
    "        {\n",
    "            \"query\": str,\n",
    "            \"label_id\": int (0=Mail, 1=Calendar),\n",
    "            \"label_name\": str,\n",
    "            \"confidence\": float (0-1),\n",
    "            \"time_range\": dict or None,\n",
    "            \"people\": list,\n",
    "            \"summary\": str (human-readable)\n",
    "        }\n",
    "    \"\"\"\n",
    "    # 1) Classify\n",
    "    label_id = predict_class(query)\n",
    "    label_name = \"Mail\" if label_id == 0 else \"Calendar\"\n",
    "    \n",
    "    # 2) Extract time range (best for Calendar)\n",
    "    time_range = extract_time_range(query) if label_id == 1 else None\n",
    "    \n",
    "    # 3) Extract people\n",
    "    people = extract_people(query)\n",
    "    \n",
    "    # 4) Build human-readable summary\n",
    "    summary = f\"{label_name} query\"\n",
    "    if people:\n",
    "        summary += f\" | People: {', '.join(people)}\"\n",
    "    if time_range:\n",
    "        summary += f\" | Time: {time_range['from']} to {time_range['to']}\"\n",
    "    \n",
    "    return {\n",
    "        \"query\": query,\n",
    "        \"label_id\": label_id,\n",
    "        \"label_name\": label_name,\n",
    "        \"time_range\": time_range,\n",
    "        \"people\": people,\n",
    "        \"summary\": summary\n",
    "    }\n",
    "\n",
    "# Test unified analysis\n",
    "unified_test_queries = [\n",
    "    \"Find emails with PDF attachments\",\n",
    "    \"Show me all events scheduled for next Tuesday\",\n",
    "    \"Search for unread messages in my inbox\",\n",
    "    \"When is my next meeting with the design team?\",\n",
    "    \"Find messages with subject line 'quarterly report'\",\n",
    "    \"Show me all-day events in May\",\n",
    "    \"Find emails from Sarah about project proposal\",\n",
    "    \"Find appointments with Dr. Johnson\",\n",
    "    \"Find my meetings for June 2025\",\n",
    "]\n",
    "\n",
    "print(\"\\nTesting analyze_query() unified function:\\n\")\n",
    "\n",
    "for q in unified_test_queries:\n",
    "    result = analyze_query(q)\n",
    "    print(f\"Query: {q}\")\n",
    "    print(f\"  Label:      [{result['label_id']}] {result['label_name']}\")\n",
    "    print(f\"  Time range: {result['time_range']}\")\n",
    "    print(f\"  People:     {result['people']}\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-04T14:06:29.691509Z",
     "iopub.status.busy": "2025-12-04T14:06:29.691212Z",
     "iopub.status.idle": "2025-12-04T14:06:29.85705Z",
     "shell.execute_reply": "2025-12-04T14:06:29.856294Z",
     "shell.execute_reply.started": "2025-12-04T14:06:29.691486Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Device setup\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else (\"cuda\" if torch.cuda.is_available() else \"cpu\"))\n",
    "\n",
    "# Model path (update this to your actual model directory)\n",
    "MODEL_DIR = \"../models/trained/distilbert_trained/\"\n",
    "MAX_LEN = 128\n",
    "\n",
    "@lru_cache(maxsize=1)\n",
    "def _load_model_and_tokenizer():\n",
    "    \"\"\"Load model and tokenizer once (cached for efficiency)\"\"\"\n",
    "    tokenizer = AutoTokenizer.from_pretrained(MODEL_DIR)\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(MODEL_DIR)\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    return tokenizer, model\n",
    "\n",
    "def predict_class(test_query: str) -> int:\n",
    "    \"\"\"\n",
    "    Classify a query as Gmail (0) or Calendar (1)\n",
    "    \n",
    "    Args:\n",
    "        test_query: User's query string\n",
    "        \n",
    "    Returns:\n",
    "        int: 0 for Gmail, 1 for Calendar\n",
    "    \"\"\"\n",
    "    tokenizer, model = _load_model_and_tokenizer()\n",
    "    \n",
    "    # Tokenize\n",
    "    encoding = tokenizer(\n",
    "        test_query,\n",
    "        return_tensors='pt',\n",
    "        truncation=True,\n",
    "        padding=True,\n",
    "        max_length=MAX_LEN\n",
    "    )\n",
    "    \n",
    "    # Move to device\n",
    "    encoding = {k: v.to(device) for k, v in encoding.items()}\n",
    "    \n",
    "    # Predict\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**encoding)\n",
    "        logits = outputs.logits\n",
    "        prediction = torch.argmax(logits, dim=-1).item()\n",
    "    \n",
    "    return int(prediction)\n",
    "\n",
    "# Test it\n",
    "if __name__ == \"__main__\":\n",
    "    print(predict_class(\"Find emails with PDF attachments\"))  \n",
    "    print(predict_class(\"Show me all events scheduled for next Tuesday\"))  \n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 8917131,
     "sourceId": 13990956,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8917201,
     "sourceId": 13991254,
     "sourceType": "datasetVersion"
    },
    {
     "isSourceIdPinned": false,
     "modelId": 524128,
     "modelInstanceId": 509460,
     "sourceId": 672429,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 31192,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
